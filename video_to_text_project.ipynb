{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iiney/colabbb/blob/main/video_to_text_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp2oKeznETrB"
      },
      "source": [
        "# 影片--whisper ai--文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSj0C2GONb3S",
        "outputId": "035c70b7-488a-4085-ee4c-3a6edf896ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlfTmzVBOHfS",
        "outputId": "9a816017-5bb0-40ed-8d33-5333beb4f2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n"
      ],
      "metadata": {
        "id": "3JJ7vHTPsGIB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-XXIjTGPHhq",
        "outputId": "9230a70a-2982-483f-ed01-5a549ef8f71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m665.6/800.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=4d7de757b2ef0acdd056d7b3004127371714ee91247d1741436986e3f65acc14\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,032 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,596 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,403 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,372 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,650 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,450 kB]\n",
            "Fetched 18.9 MB in 4s (5,174 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper\n",
        "\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I775NRcsUfdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3062a89e-aa05-4e04-9398-137116869345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 86.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "#import whisper library / load Whisper automatic speech recognition (ASR) base model\n",
        "import whisper\n",
        "import os  # Import the os module\n",
        "from google.colab import files\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tVvqwLe_MkSv"
      },
      "outputs": [],
      "source": [
        "audio_path = \"/content/drive/MyDrive/0529MB.mp4\"\n",
        "\n",
        "\n",
        "#result = model.transcribe(\"C:\\Users\\irene\\Desktop\\lectureStream.mp4\")\n",
        "result = model.transcribe(audio_path, prompt=\"今天, 點名，禮拜，上課\")\n",
        "\n",
        "# Extract and display a portion of the transcribed text\n",
        "transcribed_text = result[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 分段"
      ],
      "metadata": {
        "id": "569o3Y4OD75n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_paragraph(text, max_length):\n",
        "    \"\"\"\n",
        "    Splits a long paragraph into multiple paragraphs with a maximum length.\n",
        "\n",
        "    Args:\n",
        "    text (str): The long paragraph to be split.\n",
        "    max_length (int): The maximum length of each paragraph.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of paragraphs.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    paragraphs = []\n",
        "    current_paragraph = []\n",
        "\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        # If adding the next word exceeds the max length, finalize the current paragraph\n",
        "        if current_length + len(word) + 1 > max_length:  # +1 for the space\n",
        "            paragraphs.append(' '.join(current_paragraph))\n",
        "            current_paragraph = [word]\n",
        "            current_length = len(word)\n",
        "        else:\n",
        "            current_paragraph.append(word)\n",
        "            current_length += len(word) + 1  # +1 for the space\n",
        "\n",
        "    # Add the last paragraph if any words remain\n",
        "    if current_paragraph:\n",
        "        paragraphs.append(' '.join(current_paragraph))\n",
        "\n",
        "    return paragraphs\n",
        "\n",
        "printed_output = \"\"\n",
        "\n",
        "\n",
        "# Example usage\n",
        "long_paragraph = transcribed_text\n",
        "max_length = 2000\n",
        "split_paragraphs = split_paragraph(long_paragraph, max_length)\n",
        "\n",
        "for i, para in enumerate(split_paragraphs):\n",
        "    # Concatenate the output strings together\n",
        "    printed_output += f\"Paragraph {i+1}:\\n\"\n",
        "    printed_output += para + \"\\n\\n\"\n",
        "\n",
        "# Now the printed output is stored in the printed_output variable\n",
        "#print(printed_output)\n"
      ],
      "metadata": {
        "id": "vobS9o1xDuFb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi9p1hPBEGuZ"
      },
      "source": [
        "# 化簡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ysJQIp9cdK7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d9c0d0-81e5-48d6-a723-94030090fbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google.generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google.generativeai) (1.24.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google.generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google.generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google.generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google.generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google.generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google.generativeai) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install google.generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "belvtqNoz7sE"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#檢查 api authentication\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "API_KEY =\n",
        "url = f\"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key={API_KEY}\"\n",
        "\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [\n",
        "                {\"text\": \"Give me five subcategories of jazz?\"}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "# Make the API request\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "# Pretty-print the JSON response\n",
        "response_json = response.json()\n",
        "print(json.dumps(response_json, indent=4))\n"
      ],
      "metadata": {
        "id": "HPEMXXGq6QW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922fcd58-2b46-4a32-d0fe-00e0157c5f18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"candidates\": [\n",
            "        {\n",
            "            \"content\": {\n",
            "                \"parts\": [\n",
            "                    {\n",
            "                        \"text\": \"1. Bebop\\n2. Hardbop\\n3. Cool Jazz\\n4. Free Jazz\\n5. Fusion\"\n",
            "                    }\n",
            "                ],\n",
            "                \"role\": \"model\"\n",
            "            },\n",
            "            \"finishReason\": \"STOP\",\n",
            "            \"index\": 0,\n",
            "            \"safetyRatings\": [\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                },\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                },\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                },\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"usageMetadata\": {\n",
            "        \"promptTokenCount\": 9,\n",
            "        \"candidatesTokenCount\": 23,\n",
            "        \"totalTokenCount\": 32\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "api_key = \"AIzaSyAyBjk_KDd0GbWpVFjtfbRGA7T1IoKuT2c\"\n",
        "\n",
        "def generate_gemini_content(transcribed_text, prompt, api_key):\n",
        "    # Define the URL\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key={api_key}\"\n",
        "\n",
        "    # Define the request data\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt + transcribed_text}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Define the headers\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "    }\n",
        "\n",
        "    # Make the POST request\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Extract the generated content from the response JSON\n",
        "        generated_content = response.json()['candidates'][0]['content']\n",
        "\n",
        "        # Extract and return the summary for each paragraph\n",
        "        return [part['text'] for part in generated_content['parts']]\n",
        "    else:\n",
        "        # If the request was not successful, print an error message and return None\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "transcribed_text = printed_output\n",
        "prompt = \"Please summarize the following content according to each paragraph and note the key points\"\n",
        "\n",
        "# Generate the summaries for each paragraph\n",
        "summaries = generate_gemini_content(transcribed_text, prompt, api_key)\n"
      ],
      "metadata": {
        "id": "HY6t65-5TU2y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated summaries\n",
        "if summaries:\n",
        "    for i, summary in enumerate(summaries, start=1):\n",
        "        print(f\"Summary for Paragraph {i}:\")\n",
        "        print(summary)\n",
        "else:\n",
        "    print(\"Failed to generate summaries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO2eHaWQlT95",
        "outputId": "d9963ab4-97c1-4c88-a383-4f3534dc64f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for Paragraph 1:\n",
            "**Paragraph 1:**\n",
            "* Summary: Discusses the historical background and significance of access to public services.\n",
            "* Key Points:\n",
            "    * Access to public services has been a long-standing issue.\n",
            "    * Governments play a crucial role in providing essential services.\n",
            "    * Digital technologies have the potential to improve access and efficiency.\n",
            "\n",
            "**Paragraph 2:**\n",
            "* Summary: Explores the role of digital technologies in expanding access to public services.\n",
            "* Key Points:\n",
            "    * Digital technologies can enhance convenience, reduce barriers, and cater to diverse needs.\n",
            "    * Innovations like mobile apps, online platforms, and e-governance initiatives facilitate access.\n",
            "    * Digital tools empower citizens, promote inclusion, and enable personalized service delivery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# Extract the file name without extension\n",
        "file_name_with_ext = os.path.basename(audio_path)\n",
        "file_name = os.path.splitext(file_name_with_ext)[0]\n",
        "\n",
        "# Extract the specific part '0521' from '0521MB'\n",
        "extracted_part = file_name[:4]  # Assuming the first 4 characters represent '0521'\n",
        "\n",
        "# Save the result as a txt file using the extracted part\n",
        "txt_filename = f\"{extracted_part}上課筆記.txt\"\n",
        "with open(txt_filename, \"w\") as file:\n",
        "    for i, summary in enumerate(summaries, start=1):\n",
        "        file.write(f\"Summary for Paragraph {i}:\\n\")\n",
        "        file.write(summary + \"\\n\\n\")\n",
        "\n",
        "# Download the file\n",
        "files.download(txt_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gZOo4TvHlljx",
        "outputId": "46878602-5c26-40b0-ab18-6443dcdd31ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12041b97-0228-4064-acce-089a445d7498\", \"0529\\u4e0a\\u8ab2\\u7b46\\u8a18.txt\", 789)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3p1--k7hl9vj"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}