{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iiney/colabbb/blob/main/video_to_text_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp2oKeznETrB"
      },
      "source": [
        "# 影片--whisper ai--文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSj0C2GONb3S",
        "outputId": "035c70b7-488a-4085-ee4c-3a6edf896ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlfTmzVBOHfS",
        "outputId": "9a816017-5bb0-40ed-8d33-5333beb4f2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n"
      ],
      "metadata": {
        "id": "3JJ7vHTPsGIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-XXIjTGPHhq",
        "outputId": "9230a70a-2982-483f-ed01-5a549ef8f71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m665.6/800.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=4d7de757b2ef0acdd056d7b3004127371714ee91247d1741436986e3f65acc14\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,032 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,596 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,403 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,372 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,650 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,450 kB]\n",
            "Fetched 18.9 MB in 4s (5,174 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper\n",
        "\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I775NRcsUfdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3062a89e-aa05-4e04-9398-137116869345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 86.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "#import whisper library / load Whisper automatic speech recognition (ASR) base model\n",
        "import whisper\n",
        "import os  # Import the os module\n",
        "from google.colab import files\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tVvqwLe_MkSv"
      },
      "outputs": [],
      "source": [
        "audio_path = \"/content/drive/MyDrive/0530MB.mp4\"\n",
        "\n",
        "\n",
        "result = model.transcribe(audio_path, prompt=\"今天, 點名，禮拜，上課\")\n",
        "\n",
        "# Extract and display a portion of the transcribed text\n",
        "transcribed_text = result[\"text\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 分段"
      ],
      "metadata": {
        "id": "569o3Y4OD75n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_paragraph(text, max_length):\n",
        "    \"\"\"\n",
        "    Splits a long paragraph into multiple paragraphs with a maximum length.\n",
        "\n",
        "    Args:\n",
        "    text (str): The long paragraph to be split.\n",
        "    max_length (int): The maximum length of each paragraph.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of paragraphs.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    paragraphs = []\n",
        "    current_paragraph = []\n",
        "\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        # If adding the next word exceeds the max length, finalize the current paragraph\n",
        "        if current_length + len(word) + 1 > max_length:  # +1 for the space\n",
        "            paragraphs.append(' '.join(current_paragraph))\n",
        "            current_paragraph = [word]\n",
        "            current_length = len(word)\n",
        "        else:\n",
        "            current_paragraph.append(word)\n",
        "            current_length += len(word) + 1  # +1 for the space\n",
        "\n",
        "    # Add the last paragraph if any words remain\n",
        "    if current_paragraph:\n",
        "        paragraphs.append(' '.join(current_paragraph))\n",
        "\n",
        "    return paragraphs\n",
        "\n",
        "printed_output = \"\"\n",
        "\n",
        "\n",
        "# Example usage\n",
        "long_paragraph = transcribed_text\n",
        "max_length = 2000\n",
        "split_paragraphs = split_paragraph(long_paragraph, max_length)\n",
        "\n",
        "for i, para in enumerate(split_paragraphs):\n",
        "    # Concatenate the output strings together\n",
        "    printed_output += f\"Paragraph {i+1}:\\n\"\n",
        "    printed_output += para + \"\\n\\n\"\n",
        "\n",
        "# Now the printed output is stored in the printed_output variable\n",
        "#print(printed_output)\n"
      ],
      "metadata": {
        "id": "vobS9o1xDuFb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi9p1hPBEGuZ"
      },
      "source": [
        "# 化簡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ysJQIp9cdK7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6979c6bc-10c9-45cd-91ce-2c61aef6c135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google.generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google.generativeai) (1.24.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google.generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google.generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google.generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google.generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google.generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google.generativeai) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install google.generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "belvtqNoz7sE"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#檢查 api authentication\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "API_KEY = ,
        "url = f\"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key={API_KEY}\"\n",
        "\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [\n",
        "                {\"text\": \"Give me five subcategories of jazz?\"}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "# Make the API request\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "# Pretty-print the JSON response\n",
        "response_json = response.json()\n",
        "print(json.dumps(response_json, indent=4))\n"
      ],
      "metadata": {
        "id": "HPEMXXGq6QW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dd8883-66cc-4b79-aa6d-83e2e2a20597"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"candidates\": [\n",
            "        {\n",
            "            \"content\": {\n",
            "                \"parts\": [\n",
            "                    {\n",
            "                        \"text\": \"1. Traditional Jazz\\n2. Bebop\\n3. Cool Jazz\\n4. Hard Bop\\n5. Free Jazz\"\n",
            "                    }\n",
            "                ],\n",
            "                \"role\": \"model\"\n",
            "            },\n",
            "            \"finishReason\": \"STOP\",\n",
            "            \"index\": 0,\n",
            "            \"safetyRatings\": [\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                },\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                },\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                },\n",
            "                {\n",
            "                    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
            "                    \"probability\": \"NEGLIGIBLE\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"usageMetadata\": {\n",
            "        \"promptTokenCount\": 9,\n",
            "        \"candidatesTokenCount\": 24,\n",
            "        \"totalTokenCount\": 33\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "api_key = \"AIzaSyAyBjk_KDd0GbWpVFjtfbRGA7T1IoKuT2c\"\n",
        "\n",
        "def generate_gemini_content(transcribed_text, prompt, api_key):\n",
        "    # Define the URL\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key={api_key}\"\n",
        "\n",
        "    # Define the request data\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt + transcribed_text}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Define the headers\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "    }\n",
        "\n",
        "    # Make the POST request\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Extract the generated content from the response JSON\n",
        "        generated_content = response.json()['candidates'][0]['content']\n",
        "\n",
        "        # Extract and return the summary for each paragraph\n",
        "        return [part['text'] for part in generated_content['parts']]\n",
        "    else:\n",
        "        # If the request was not successful, print an error message and return None\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "transcribed_text = printed_output\n",
        "prompt = \"Please summarize the following content according to each paragraph and note the key points\"\n",
        "\n",
        "# Generate the summaries for each paragraph\n",
        "summaries = generate_gemini_content(transcribed_text, prompt, api_key)\n"
      ],
      "metadata": {
        "id": "HY6t65-5TU2y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated summaries\n",
        "if summaries:\n",
        "    for i, summary in enumerate(summaries, start=1):\n",
        "        print(f\"Summary for Paragraph {i}:\")\n",
        "        print(summary)\n",
        "else:\n",
        "    print(\"Failed to generate summaries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO2eHaWQlT95",
        "outputId": "35be9458-9e4c-439d-9e03-b31a9ddf26c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for Paragraph 1:\n",
            "**Paragraph 1**\n",
            "* Key points:\n",
            "    * List of students who participated in class\n",
            "    * Review of previous lecture (coverage from page 139 to 237)\n",
            "    * New topic: Starting from Chapter 8 (page 237)\n",
            "\n",
            "**Paragraph 2**\n",
            "* Key points:\n",
            "    * Online grading system not yet finalized\n",
            "    * Content from Chapter 8 (page 237 to 370) will be covered\n",
            "    * Concepts will be similar to previous chapters, with a focus on additional factors (\"factors\")\n",
            "    * Focus on \"splicing so some\" (intron removal)\n",
            "    * \"Snaps\" proteins bind to introns and facilitate splicing\n",
            "    * SNRN8 molecule plays a role in snaps binding and intron removal\n",
            "\n",
            "**Paragraph 3**\n",
            "* Key points:\n",
            "    * Different classes of introns exist\n",
            "    * Group 1 introns are self-splicing\n",
            "    * Group 2 and 3 introns require specific adenosine sequences to initiate splicing\n",
            "    * Splicing process involves several protein complexes and the SNRN8 molecule\n",
            "    * 5' end of intron is cleaved first, followed by the 3' end\n",
            "    * Intron is removed and exons are joined together\n",
            "\n",
            "**Paragraph 4**\n",
            "* Key points:\n",
            "    * Alternative splicing: A single gene can produce multiple protein isoforms by varying the exons that are included\n",
            "    * Alternative promoter selection and alternative tail site selection can also contribute to protein diversity\n",
            "    * Trans-splicing and alternative splicing are involved in producing a variety of protein isoforms\n",
            "\n",
            "**Paragraph 5**\n",
            "* Key points:\n",
            "    * Introns are removed from RNA by splicing\n",
            "    * GT-AG sequence is a common intron recognition site\n",
            "    * Splicing factors (proteins) recognize specific sequences and facilitate intron removal\n",
            "    * Splicing process occurs in multiple steps, involving various proteins and enzymes\n",
            "    * Capping and tailing of RNA occur after splicing\n",
            "\n",
            "**Paragraph 6**\n",
            "* Key points:\n",
            "    * Protein splicing involves the removal of \"inten\" sequences from proteins\n",
            "    * Inten sequences are analogous to introns in RNA\n",
            "    * Specific enzymes (protein splicers) recognize and cleave inten sequences\n",
            "    * Protein splicing is similar to RNA splicing, but it does not require the same complex machinery\n",
            "\n",
            "**Paragraph 7**\n",
            "* Key points:\n",
            "    * RNA degradation involves removal of the cap and tail and subsequent cleavage by exonucleases\n",
            "    * Gene conversion repair: Damaged DNA can be repaired by using homologous sequences from another chromosome\n",
            "\n",
            "**Paragraph 8**\n",
            "* Key points:\n",
            "    * Base modifications can occur in RNA molecules\n",
            "    * Editing enzymes can alter specific RNA sequences\n",
            "\n",
            "**Paragraph 9**\n",
            "* Key points:\n",
            "    * Proteasome: A protein complex that degrades damaged or misfolded proteins\n",
            "    * Ubiquitination: A process where proteins are tagged with ubiquitin, marking them for degradation by the proteasome\n",
            "\n",
            "**Paragraph 10**\n",
            "* Key points:\n",
            "    * Lysosomes: Organelles that contain digestive enzymes\n",
            "    * Proteases: Enzymes that degrade proteins\n",
            "    * Lysosomes can degrade proteins both from within and outside the cell\n",
            "\n",
            "**Paragraph 11**\n",
            "* Key points:\n",
            "    * Protein structure: Central carbon atom with amino acid side chains attached\n",
            "    * Amino acids are joined by peptide bonds\n",
            "    * Polypeptides are chains of amino acids\n",
            "    * N-terminal and C-terminal ends of proteins are important for protein function and localization\n",
            "\n",
            "**Paragraph 12**\n",
            "* Key points:\n",
            "    * Hydrophobic and hydrophilic amino acids\n",
            "    * 20 standard amino acids\n",
            "    * Genetic code: 64 codons representing 20 amino acids\n",
            "    * Transfer RNA (tRNA) molecules carry amino acids to the ribosome\n",
            "    * Ribosome: A complex structure that catalyzes protein synthesis\n",
            "\n",
            "**Paragraph 13**\n",
            "* Key points:\n",
            "    * Ribosome binding site (RBS) is a sequence on mRNA that the ribosome recognizes and binds to\n",
            "    * Initiation factors (IFs) assist in the initiation of translation\n",
            "    * Release factors (RFs) recognize stop codons and terminate translation\n",
            "    * Ribosome recycling factors enable ribosomes to be reused for multiple rounds of translation\n",
            "    * Polyribosomes: Multiple ribosomes translating the same mRNA simultaneously\n",
            "\n",
            "**Paragraph 14**\n",
            "* Key points:\n",
            "    * Bacteria have a higher proportion of coding regions in their genes (polycistronic mRNA)\n",
            "    * Transcription and translation can occur simultaneously in bacteria\n",
            "    * Coupled transcription and translation allows bacteria to rapidly produce proteins\n",
            "\n",
            "**Paragraph 15**\n",
            "* Key points:\n",
            "    * Eukaryotic cells undergo more extensive post-transcriptional modifications (capping, tailing, splicing) before translation\n",
            "    * Prokaryotic cells (bacteria) have less complex gene regulation and simpler protein synthesis processes\n",
            "\n",
            "**Paragraph 16**\n",
            "* Key points:\n",
            "    * Review of chapter highlights\n",
            "    * Areas to focus on for upcoming exam: 139-237 (previous lecture), Chapter 8 (new content)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# Extract the file name without extension\n",
        "file_name_with_ext = os.path.basename(audio_path)\n",
        "file_name = os.path.splitext(file_name_with_ext)[0]\n",
        "\n",
        "# Extract the specific part '0521' from '0521MB'\n",
        "extracted_part = file_name[:4]  # Assuming the first 4 characters represent '0521'\n",
        "\n",
        "# Save the result as a txt file using the extracted part\n",
        "txt_filename = f\"{extracted_part}上課筆記.txt\"\n",
        "with open(txt_filename, \"w\") as file:\n",
        "    for i, summary in enumerate(summaries, start=1):\n",
        "        file.write(f\"Summary for Paragraph {i}:\\n\")\n",
        "        file.write(summary + \"\\n\\n\")\n",
        "\n",
        "# Download the file\n",
        "files.download(txt_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gZOo4TvHlljx",
        "outputId": "199fa630-82d5-43d2-b215-f5b5484f775a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0cee79d5-c7f2-4b74-a465-a6510101de01\", \"0530\\u4e0a\\u8ab2\\u7b46\\u8a18.txt\", 4735)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3p1--k7hl9vj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
